{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPr4a9t6P9COr5NRS7hRJsO",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/samantha-isaac/Emotion-Detection-in-Images-and-Music-Pairing-Through-AI/blob/main/CNN_SVM_FTuning_Landscape.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CNNs with SVMs Grid Search for Landscape Dataset\n",
        "\n",
        "Samantha Isaac"
      ],
      "metadata": {
        "id": "BSjKSrAwZlEK"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KV5L33DDunU0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPooling2D, Dropout, Flatten, Dense\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import seaborn as sns\n",
        "import os\n",
        "import cv2\n",
        "from google.colab import drive\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import train_test_split"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This is to mount Drive to this project\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bKs86qVsurCB",
        "outputId": "bf75828f-f89d-4f72-e05c-9619a108f663"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Path to the folder for the Landscape dataset\n",
        "dataset_folder = '/content/drive/MyDrive/Dissertation/Code/Data_Landscapes'"
      ],
      "metadata": {
        "id": "HnEimlbSuskh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This function helps load the images and assigns as the labels the name of the correspodning folder\n",
        "# References used for the function with os: https://docs.python.org/3/library/os.html\n",
        "def load_images_and_labels(folder_path):\n",
        "    images = []\n",
        "    labels = []\n",
        "    sub_folders = os.listdir(folder_path)\n",
        "\n",
        "    for sub_folder in sub_folders:\n",
        "        label = sub_folder # In here is where the name of the sub folders is taken as the label\n",
        "        image_files = os.listdir(os.path.join(folder_path, sub_folder))\n",
        "\n",
        "        for image_file in image_files:\n",
        "            image_path = os.path.join(folder_path, sub_folder, image_file)\n",
        "            image = cv2.imread(image_path, cv2.IMREAD_COLOR) # It reads the images in BGR\n",
        "            if image is not None:\n",
        "                image = cv2.resize(image, (128, 128))  # Redimention the images\n",
        "                image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB) # This is to convert from BGR to RGB\n",
        "                # Reference for this: https://docs.opencv.org/4.x/d4/da8/group__imgcodecs.html\n",
        "                images.append(image)\n",
        "                labels.append(label)\n",
        "\n",
        "    return np.array(images), labels"
      ],
      "metadata": {
        "id": "bJvFe8fkuyZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To load images and labels\n",
        "images, labels = load_images_and_labels(dataset_folder)"
      ],
      "metadata": {
        "id": "4aDGqOw9u0ej"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To create the training and testing sets\n",
        "train_images, test_images, train_labels, test_labels = train_test_split(images, labels, test_size=0.3, random_state=42, stratify=labels)"
      ],
      "metadata": {
        "id": "Z1nEIQMXu8YQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To crerate a dictionary that assigns a numeric value to each label\n",
        "label_map = {label: idx for idx, label in enumerate(set(train_labels))}\n",
        "# For both training and testing dataset, it replace the label with the correspodning numeric value stablich in the line above\n",
        "train_labels_numeric = [label_map[label] for label in train_labels]\n",
        "test_labels_numeric = [label_map[label] for label in test_labels]"
      ],
      "metadata": {
        "id": "dZS6N5XJu-jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoding. Reference from: https://www.tensorflow.org/api_docs/python/tf/keras/utils/to_categorical\n",
        "num_classes = len(label_map)\n",
        "train_labels_encoded = to_categorical(train_labels_numeric, num_classes=num_classes)\n",
        "test_labels_encoded = to_categorical(test_labels_numeric, num_classes=num_classes)"
      ],
      "metadata": {
        "id": "QZ1MPDaxu_4x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To normalize and to convert in arrays of NumPy. Reference from: https://numpy.org/doc/stable/reference/generated/numpy.array.html\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "# To verify that the asignation of the values was made correctly\n",
        "print(\"Mapping of labels to numeric values:\")\n",
        "print(label_map)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAmdKzF8vCdr",
        "outputId": "7dda5ef5-5e6d-45c2-9128-7e188b79b708"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mapping of labels to numeric values:\n",
            "{'joy': 0, 'melancholy': 1, 'liveliness': 2, 'sadness': 3}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# This was an extra added to improve the generalisability of the model, generating new modified versions of the images\n",
        "datagen = ImageDataGenerator(\n",
        "    rotation_range = 10,\n",
        "    width_shift_range = 0.1,\n",
        "    height_shift_range = 0.1,\n",
        "    zoom_range = 0.1,\n",
        "    horizontal_flip = True\n",
        ")\n",
        "\n",
        "datagen.fit(train_images)"
      ],
      "metadata": {
        "id": "HDy4lXBevD8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Stablish the structure of the CNN model. Used a reference for most of the structure of the models\n",
        "# the project of: https://medium.com/@skillcate/emotion-detection-model-using-cnn-a-complete-guide-831db1421fael\n",
        "def build_feature_extractor(activation = 'relu', dropout_rate = 0.5, l2_rate = 0.001):\n",
        "    input = Input(shape = (128, 128, 3))\n",
        "\n",
        "    conv1 = Conv2D(64, (3, 3), padding = 'same', strides = (1, 1), kernel_regularizer = l2(l2_rate))(input)\n",
        "    conv1 = BatchNormalization()(conv1)\n",
        "    conv1 = Activation(activation)(conv1)\n",
        "    pool1 = MaxPooling2D(pool_size = (2, 2))(conv1)\n",
        "    pool1 = Dropout(dropout_rate)(pool1)\n",
        "\n",
        "    conv2 = Conv2D(128, (3, 3), padding = 'same', strides = (1, 1), kernel_regularizer = l2(l2_rate))(pool1)\n",
        "    conv2 = BatchNormalization()(conv2)\n",
        "    conv2 = Activation(activation)(conv2)\n",
        "    pool2 = MaxPooling2D(pool_size = (2, 2))(conv2)\n",
        "    pool2 = Dropout(dropout_rate)(pool2)\n",
        "\n",
        "    conv3 = Conv2D(256, (3, 3), padding = 'same', strides = (1, 1), kernel_regularizer = l2(l2_rate))(pool2)\n",
        "    conv3 = BatchNormalization()(conv3)\n",
        "    conv3 = Activation(activation)(conv3)\n",
        "    pool3 = MaxPooling2D(pool_size = (2, 2))(conv3)\n",
        "    pool3 = Dropout(dropout_rate)(pool3)\n",
        "\n",
        "    conv4 = Conv2D(512, (3, 3), padding = 'same', strides = (1, 1), kernel_regularizer = l2(l2_rate))(pool3)\n",
        "    conv4 = BatchNormalization()(conv4)\n",
        "    conv4 = Activation(activation)(conv4)\n",
        "    pool4 = MaxPooling2D(pool_size = (2, 2))(conv4)\n",
        "    pool4 = Dropout(dropout_rate)(pool4)\n",
        "\n",
        "    flatten = Flatten()(pool4)\n",
        "    feature_output = Dense(256, activation = activation)(flatten)\n",
        "\n",
        "    feature_model = Model(inputs = input, outputs = feature_output)\n",
        "    return feature_model"
      ],
      "metadata": {
        "id": "DveOJ0--vFqw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_extractor = build_feature_extractor() # To show the structure of the model"
      ],
      "metadata": {
        "id": "TawV5kHqvaUC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# This is to extract the characteristic of the images. Reference: https://scikit-learn.org/stable/modules/feature_extraction.html\n",
        "train_features = feature_extractor.predict(train_images)\n",
        "test_features = feature_extractor.predict(test_images)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ndBgJiuHvcmR",
        "outputId": "ff5a5405-ffe6-4bc2-c6dd-05a0f113cfbe"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m33/33\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 1s/step\n",
            "\u001b[1m14/14\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 2s/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I make instance of StandarScaler to normalise the data. Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "scaler = StandardScaler()\n",
        "# This adjust the scaler. Reference: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.StandardScaler.html\n",
        "train_features = scaler.fit_transform(train_features)\n",
        "test_features = scaler.transform(test_features)\n",
        "# This line of code creates the SVM model\n",
        "svm_model = SVC()"
      ],
      "metadata": {
        "id": "z9OD0uwtvdx5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# To stablish the diferent hyperparameters values\n",
        "svm_parameters = {\n",
        "    'C': [0.1, 1, 10, 100],\n",
        "    'kernel': ['linear', 'rbf', 'poly'],\n",
        "    'gamma': ['scale', 'auto'],\n",
        "    'degree': [2, 3, 4]\n",
        "}"
      ],
      "metadata": {
        "id": "wHZhJthgvkzi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the grid search with the previous mentioned hyperparameters\n",
        "svm_grid_search = GridSearchCV(svm_model, svm_parameters, cv = 3, verbose = 2, n_jobs = -1)\n",
        "svm_grid_search.fit(train_features, train_labels_numeric)\n",
        "\n",
        "# To print results of best combination\n",
        "print(\"Best SVM parameters:\", svm_grid_search.best_params_)\n",
        "print(\"Best SVM cross-validation score:\", svm_grid_search.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "siYtmVfSvmlA",
        "outputId": "c865a929-8543-4184-ef05-787bd352c276"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 3 folds for each of 72 candidates, totalling 216 fits\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/backend/fork_exec.py:38: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  pid = os.fork()\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best SVM parameters: {'C': 1, 'degree': 2, 'gamma': 'auto', 'kernel': 'rbf'}\n",
            "Best SVM cross-validation score: 0.48937759802269404\n"
          ]
        }
      ]
    }
  ]
}